{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32d212cd-5a88-41c5-afcb-907bbd90a407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, fbeta_score, classification_report, confusion_matrix\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a69a75-e7c8-41d1-a362-8dd7b1e9c8aa",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b43581f-94c1-4283-8f20-a219da191ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#loading data\n",
    "data = pd.read_csv('./data/processed_data.csv')\n",
    "\n",
    "# Features and labels\n",
    "X = data.drop('y', axis=1)\n",
    "y = data['y']\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=2024)\n",
    "# Split training set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29ef8169-0316-45c8-bfd7-2910e64fd6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(imb=False, batch_size=64):\n",
    "\n",
    "    if imb:\n",
    "        \n",
    "        print(\"use smote\")\n",
    "        # use smote to oversampling\n",
    "        smote = SMOTE(random_state=2024)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        X_train_tensor = torch.tensor(X_train_resampled.values, dtype=torch.float32).to(device)\n",
    "        y_train_tensor = torch.tensor(y_train_resampled.values, dtype=torch.float32).view(-1, 1).to(device)\n",
    "    else:\n",
    "        \n",
    "        X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n",
    "        y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1).to(device)\n",
    "        \n",
    "    \n",
    "    X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32).to(device)\n",
    "    X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n",
    "    \n",
    "    y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1).to(device)\n",
    "    \n",
    "    \n",
    "    # Create data loaders\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, y_val_tensor, y_test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9af6d801-c0f7-43ca-b278-88c5e92c52a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_val(epoch, val_f2_list):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        y_pred_val = []\n",
    "        \n",
    "        for X_batch, y_batch in val_loader:\n",
    "\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)            \n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            predicted = outputs.round().view(-1)\n",
    "            y_pred_val.extend(predicted.tolist())\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    y_pred_val = torch.tensor(y_pred_val)\n",
    "    \n",
    "    val_f2 = fbeta_score(y_val_tensor.cpu(), y_pred_val.cpu(), beta=2)\n",
    "    val_f2_list.append(val_f2)\n",
    "    \n",
    "    # print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}, Val F2-score: {val_f2:.4f}',end=' ')\n",
    "\n",
    "def evaluate_test(epoch, test_precision_list, test_recall_list, test_f1_list, test_f2_list):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        y_pred_test = []\n",
    "        \n",
    "        for X_batch, _ in test_loader:\n",
    "            \n",
    "            X_batch = X_batch.to(device)            \n",
    "            outputs = model(X_batch)\n",
    "            predicted = outputs.round().view(-1)\n",
    "            y_pred_test.extend(predicted.tolist())\n",
    "\n",
    "    y_pred_test = torch.tensor(y_pred_test)\n",
    "\n",
    "    test_precision = precision_score(y_test_tensor.cpu(), y_pred_test.cpu(), zero_division=1)\n",
    "    test_precision_list.append(test_precision)\n",
    "    test_recall = recall_score(y_test_tensor.cpu(), y_pred_test.cpu())\n",
    "    test_recall_list.append(test_recall)\n",
    "    test_f1 = f1_score(y_test_tensor.cpu(), y_pred_test.cpu())\n",
    "    test_f1_list.append(test_f1)\n",
    "    test_f2 = fbeta_score(y_test_tensor.cpu(), y_pred_test.cpu(), beta=2)\n",
    "    test_f2_list.append(test_f2)\n",
    "    \n",
    "    # print(f', Test F2-score:{test_f2:.4f} ,Test Recall: {test_recall:.4f}')\n",
    "\n",
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5557b23d-a474-420e-ab27-c28a0a6ba61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(model, num_epochs, train_loader, val_loader, test_loader, y_val_tensor, y_test_tensor):\n",
    "    # Best record list\n",
    "    val_f2_list = []\n",
    "\n",
    "    test_recall_list = []\n",
    "    test_precision_list = []\n",
    "    test_f1_list = []\n",
    "    test_f2_list = []\n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            # Move data to GPU\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "            optimizer.step()\n",
    "        \n",
    "        evaluate_val(epoch, val_f2_list)\n",
    "        evaluate_test(epoch, test_precision_list, test_recall_list, test_f1_list, test_f2_list)\n",
    "        \n",
    "    print(\"Done\")\n",
    "    best_index = val_f2_list.index(max(val_f2_list))\n",
    "    print(\"Best Val Score In Epoch:\", best_index+1)\n",
    "    print(\"TestDataset Best Record\")\n",
    "    print(f'Test Precision:{test_precision_list[best_index]:.4f}, Test Recll:{test_recall_list[best_index]:.4f}')\n",
    "    print(f'Test F1-score:{test_f1_list[best_index]:.4f}, Test F2-score:{test_f2_list[best_index]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1825ba68-c77a-4bfe-a879-fd7827628f4b",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7659d978-e64c-490a-a154-d1fec3fb644b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''NN'''\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_layer_dim):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_layer_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.fc5 = nn.Linear(64, 32)\n",
    "        self.fc6 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc4(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc5(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.fc6(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ab8d023-c5fd-4f5f-97f3-d18559d98365",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''CNN'''\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_layer_dim):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=5)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=5, stride=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=5, stride=1)\n",
    "        # self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=5)\n",
    "        # self.pool3 = nn.MaxPool1d(kernel_size=5, stride=1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(3968, 64)  # adjust dim78\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # one-dim\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        # x = self.relu(self.conv3(x))\n",
    "        # x = self.pool3(x)\n",
    "        x = x.view(x.size(0), -1)  # faltten\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "769f6c87-5ae5-439a-8a5f-51d0a45bd090",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''DilatedCNN'''\n",
    "class DilatedCNN(nn.Module):\n",
    "    def __init__(self, input_layer_dim):\n",
    "        super(DilatedCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=6, dilation=3)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=5, stride=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=6, dilation=3)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=5, stride=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=6, dilation=3)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=5, stride=1)\n",
    "        self.fc1 = nn.Linear(2688, 64)  # adjust dim78\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # one-dim\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = x.view(x.size(0), -1)  # faltten\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cba0e9-107b-484e-85c0-3cfc507dab1b",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b0cf919-63d0-4496-a7fd-f6803df1d05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Best Val Score In Epoch: 28\n",
      "TestDataset Best Record\n",
      "Test Precision:0.5357, Test Recll:0.7290\n",
      "Test F1-score:0.6176, Test F2-score:0.6799\n"
     ]
    }
   ],
   "source": [
    "'''NN without SMOTE'''\n",
    "# Define model, loss function, optimizer\n",
    "model = NN(X_train.values.shape[1]).to(device) # X_train.values.shape[1] is input_layer_dim\n",
    "model.apply(initialize_weights) # Initial weight\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# Get data_loader\n",
    "train_loader, val_loader, test_loader, y_val_tensor, y_test_tensor = get_data_loader(imb=False, batch_size=512)\n",
    "# Train the model\n",
    "num_epochs = 200\n",
    "training_model(model, num_epochs, train_loader, val_loader, test_loader, y_val_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d52b23b5-aebc-430c-a495-a07c2a75d326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use smote\n",
      "Done\n",
      "Best Val Score In Epoch: 4\n",
      "TestDataset Best Record\n",
      "Test Precision:0.4247, Test Recll:0.8542\n",
      "Test F1-score:0.5673, Test F2-score:0.7105\n"
     ]
    }
   ],
   "source": [
    "'''NN with SMOTE'''\n",
    "# Define model,| loss function, optimizer\n",
    "model = NN(X_train.values.shape[1]).to(device) # X_train.values.shape[1] is input_layer_dim\n",
    "model.apply(initialize_weights) # Initial weight\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# Get data_loader\n",
    "train_loader, val_loader, test_loader, y_val_tensor, y_test_tensor = get_data_loader(imb=True, batch_size=512)\n",
    "# Train the model\n",
    "num_epochs = 200\n",
    "training_model(model, num_epochs, train_loader, val_loader, test_loader, y_val_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1592927-dda1-448e-b739-0bb72647c9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Best Val Score In Epoch: 152\n",
      "TestDataset Best Record\n",
      "Test Precision:0.5444, Test Recll:0.6411\n",
      "Test F1-score:0.5888, Test F2-score:0.6191\n"
     ]
    }
   ],
   "source": [
    "'''CNN without SMOTE'''\n",
    "# Define model, loss function, optimizer\n",
    "model = CNN(X_train.values.shape[1]).to(device) # X_train.values.shape[1] is input_layer_dim\n",
    "model.apply(initialize_weights) # Initial weight\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# Get data_loader\n",
    "train_loader, val_loader, test_loader, y_val_tensor, y_test_tensor = get_data_loader(imb=False, batch_size=512)\n",
    "# Train the model\n",
    "num_epochs = 200\n",
    "training_model(model, num_epochs, train_loader, val_loader, test_loader, y_val_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca55dc77-8b5b-4ab7-ae14-1ab994e798a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use smote\n",
      "Done\n",
      "Best Val Score In Epoch: 55\n",
      "TestDataset Best Record\n",
      "Test Precision:0.3940, Test Recll:0.8897\n",
      "Test F1-score:0.5462, Test F2-score:0.7109\n"
     ]
    }
   ],
   "source": [
    "'''CNN with SMOTE'''\n",
    "# Define model, loss function, optimizer\n",
    "model = CNN(X_train.values.shape[1]).to(device) # X_train.values.shape[1] is input_layer_dim\n",
    "model.apply(initialize_weights) # Initial weight\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# Get data_loader\n",
    "train_loader, val_loader, test_loader, y_val_tensor, y_test_tensor = get_data_loader(imb=True, batch_size=512)\n",
    "# Train the model\n",
    "num_epochs = 200\n",
    "training_model(model, num_epochs, train_loader, val_loader, test_loader, y_val_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1310196b-65d8-4e64-beb0-5a44ee1e06e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Best Val Score In Epoch: 38\n",
      "TestDataset Best Record\n",
      "Test Precision:0.5134, Test Recll:0.7495\n",
      "Test F1-score:0.6094, Test F2-score:0.6864\n"
     ]
    }
   ],
   "source": [
    "'''DilatedCNNCNN without SMOTE'''\n",
    "# Define model, loss function, optimizer\n",
    "model = DilatedCNN(X_train.values.shape[1]).to(device) # X_train.values.shape[1] is input_layer_dim\n",
    "model.apply(initialize_weights) # Initial weight\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# Get data_loader\n",
    "train_loader, val_loader, test_loader, y_val_tensor, y_test_tensor = get_data_loader(imb=False, batch_size=512)\n",
    "# Train the model\n",
    "num_epochs = 200\n",
    "training_model(model, num_epochs, train_loader, val_loader, test_loader, y_val_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1f1778c-7c62-4ea2-9958-a3ed5bee587a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use smote\n",
      "Done\n",
      "Best Val Score In Epoch: 44\n",
      "TestDataset Best Record\n",
      "Test Precision:0.4319, Test Recll:0.8542\n",
      "Test F1-score:0.5738, Test F2-score:0.7145\n"
     ]
    }
   ],
   "source": [
    "'''DilatedCNNCNN with SMOTE'''\n",
    "# Define model, loss function, optimizer\n",
    "model = DilatedCNN(X_train.values.shape[1]).to(device) # X_train.values.shape[1] is input_layer_dim\n",
    "model.apply(initialize_weights) # Initial weight\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# Get data_loader\n",
    "train_loader, val_loader, test_loader, y_val_tensor, y_test_tensor = get_data_loader(imb=True, batch_size=512)\n",
    "# Train the model\n",
    "num_epochs = 200\n",
    "training_model(model, num_epochs, train_loader, val_loader, test_loader, y_val_tensor, y_test_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
